{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-16T13:44:55.511731Z","iopub.status.busy":"2021-08-16T13:44:55.51138Z","iopub.status.idle":"2021-08-16T13:44:56.261058Z","shell.execute_reply":"2021-08-16T13:44:56.259547Z","shell.execute_reply.started":"2021-08-16T13:44:55.511703Z"}},"source":["# Cycle GAN\n","![Cycle-GAN](https://miro.medium.com/max/1838/0*S5gn5i6UhfyoRr9S.png)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-16T13:46:38.780264Z","iopub.status.busy":"2021-08-16T13:46:38.779785Z","iopub.status.idle":"2021-08-16T13:46:38.784886Z","shell.execute_reply":"2021-08-16T13:46:38.784065Z","shell.execute_reply.started":"2021-08-16T13:46:38.780222Z"}},"source":["## Step 1. Define Generator"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.490755Z","iopub.status.busy":"2021-08-17T15:58:41.49037Z","iopub.status.idle":"2021-08-17T15:58:41.497139Z","shell.execute_reply":"2021-08-17T15:58:41.496097Z","shell.execute_reply.started":"2021-08-17T15:58:41.490716Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.ReflectionPad2d(1), # padding, keep the image size constant after next conv2d\n","            nn.Conv2d(in_channels, in_channels, 3),\n","            nn.InstanceNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_channels, in_channels, 3),\n","            nn.InstanceNorm2d(in_channels)\n","        )\n","    \n","    def forward(self, x):\n","        return x + self.block(x)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.499567Z","iopub.status.busy":"2021-08-17T15:58:41.499036Z","iopub.status.idle":"2021-08-17T15:58:41.513241Z","shell.execute_reply":"2021-08-17T15:58:41.512368Z","shell.execute_reply.started":"2021-08-17T15:58:41.499533Z"},"trusted":true},"outputs":[],"source":["class GeneratorResNet(nn.Module):\n","    def __init__(self, in_channels, num_residual_blocks=9):\n","        super(GeneratorResNet, self).__init__()\n","        \n","        # Inital Convolution  3*256*256 -> 64*256*256\n","        out_channels=64\n","        self.conv = nn.Sequential(\n","            nn.ReflectionPad2d(in_channels), # padding, keep the image size constant after next conv2d\n","            nn.Conv2d(in_channels, out_channels, 2*in_channels+1),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","        \n","        channels = out_channels\n","        \n","        # Downsampling   64*256*256 -> 128*128*128 -> 256*64*64\n","        self.down = []\n","        for _ in range(2):\n","            out_channels = channels * 2\n","            self.down += [\n","                nn.Conv2d(channels, out_channels, 3, stride=2, padding=1),\n","                nn.InstanceNorm2d(out_channels),\n","                nn.ReLU(inplace=True),\n","            ]\n","            channels = out_channels\n","        self.down = nn.Sequential(*self.down)\n","        \n","        # Transformation (ResNet)  256*64*64\n","        self.trans = [ResidualBlock(channels) for _ in range(num_residual_blocks)]\n","        self.trans = nn.Sequential(*self.trans)\n","        \n","        # Upsampling  256*64*64 -> 128*128*128 -> 64*256*256\n","        self.up = []\n","        for _ in range(2):\n","            out_channels = channels // 2\n","            self.up += [\n","                nn.Upsample(scale_factor=2), # bilinear interpolation\n","                nn.Conv2d(channels, out_channels, 3, stride=1, padding=1),\n","                nn.InstanceNorm2d(out_channels),\n","                nn.ReLU(inplace=True),\n","            ]\n","            channels = out_channels\n","        self.up = nn.Sequential(*self.up)\n","        \n","        # Out layer  64*256*256 -> 3*256*256\n","        self.out = nn.Sequential(\n","            nn.ReflectionPad2d(in_channels),\n","            nn.Conv2d(channels, in_channels, 2*in_channels+1),\n","            nn.Tanh()\n","        )\n","    \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.down(x)\n","        x = self.trans(x)\n","        x = self.up(x)\n","        x = self.out(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T02:12:55.676929Z","iopub.status.busy":"2021-08-17T02:12:55.676304Z","iopub.status.idle":"2021-08-17T02:12:55.694692Z","shell.execute_reply":"2021-08-17T02:12:55.693976Z","shell.execute_reply.started":"2021-08-17T02:12:55.676889Z"}},"source":["## Step 2. Define Discriminator"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.515239Z","iopub.status.busy":"2021-08-17T15:58:41.514877Z","iopub.status.idle":"2021-08-17T15:58:41.526006Z","shell.execute_reply":"2021-08-17T15:58:41.525026Z","shell.execute_reply.started":"2021-08-17T15:58:41.515205Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_channels):\n","        super(Discriminator, self).__init__()\n","        \n","        self.model = nn.Sequential(\n","            # why normalize=False?\n","            *self.block(in_channels, 64, normalize=False), # 3*256*256 -> 64*128*128 \n","            *self.block(64, 128),  # 64*128*128 -> 128*64*64\n","            *self.block(128, 256), # 128*64*64 -> 256*32*32\n","            *self.block(256, 512), # 256*32*32 -> 512*16*16\n","            \n","            # Why padding first then convolution?\n","            nn.ZeroPad2d((1,0,1,0)), # padding left and top   512*16*16 -> 512*17*17\n","            nn.Conv2d(512, 1, 4, padding=1) # 512*17*17 -> 1*16*16\n","        )\n","        \n","        self.scale_factor = 16\n","    \n","    @staticmethod\n","    def block(in_channels, out_channels, normalize=True):\n","        layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n","        if normalize:\n","            layers.append(nn.InstanceNorm2d(out_channels))\n","        layers.append(nn.LeakyReLU(0.2, inplace=True))\n","        \n","        return layers\n","        \n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T03:15:37.92481Z","iopub.status.busy":"2021-08-17T03:15:37.924281Z","iopub.status.idle":"2021-08-17T03:15:38.24994Z","shell.execute_reply":"2021-08-17T03:15:38.249301Z","shell.execute_reply.started":"2021-08-17T03:15:37.924769Z"}},"source":["## Step 3. Define Loss"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.527514Z","iopub.status.busy":"2021-08-17T15:58:41.527169Z","iopub.status.idle":"2021-08-17T15:58:41.53658Z","shell.execute_reply":"2021-08-17T15:58:41.535753Z","shell.execute_reply.started":"2021-08-17T15:58:41.527481Z"},"trusted":true},"outputs":[],"source":["criterion_GAN = nn.MSELoss()\n","criterion_cycle = nn.L1Loss()\n","criterion_identity = nn.L1Loss()"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4. Initalize G and D"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.538008Z","iopub.status.busy":"2021-08-17T15:58:41.537649Z","iopub.status.idle":"2021-08-17T15:58:41.786092Z","shell.execute_reply":"2021-08-17T15:58:41.785252Z","shell.execute_reply.started":"2021-08-17T15:58:41.537974Z"},"trusted":true},"outputs":[],"source":["G_AB = GeneratorResNet(3, num_residual_blocks=9)\n","D_B = Discriminator(3)\n","\n","G_BA = GeneratorResNet(3, num_residual_blocks=9)\n","D_A = Discriminator(3)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:41.787674Z","iopub.status.busy":"2021-08-17T15:58:41.787281Z","iopub.status.idle":"2021-08-17T15:58:46.083715Z","shell.execute_reply":"2021-08-17T15:58:46.082855Z","shell.execute_reply.started":"2021-08-17T15:58:41.78764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda: True\n"]}],"source":["cuda = torch.cuda.is_available()\n","print(f'cuda: {cuda}')\n","if cuda:\n","    G_AB = G_AB.cuda()\n","    D_B = D_B.cuda()\n","    G_BA = G_BA.cuda()\n","    D_A = D_A.cuda()\n","    \n","    criterion_GAN = criterion_GAN.cuda()\n","    criterion_cycle = criterion_cycle.cuda()\n","    criterion_identity = criterion_identity.cuda()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T03:20:13.704889Z","iopub.status.busy":"2021-08-17T03:20:13.704545Z","iopub.status.idle":"2021-08-17T03:20:13.710944Z","shell.execute_reply":"2021-08-17T03:20:13.709978Z","shell.execute_reply.started":"2021-08-17T03:20:13.704859Z"}},"source":["## Step 5. Configure Optimizers"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.08658Z","iopub.status.busy":"2021-08-17T15:58:46.086219Z","iopub.status.idle":"2021-08-17T15:58:46.095901Z","shell.execute_reply":"2021-08-17T15:58:46.095133Z","shell.execute_reply.started":"2021-08-17T15:58:46.086544Z"},"trusted":true},"outputs":[],"source":["import itertools\n","lr = 0.0002\n","b1 = 0.5\n","b2 = 0.999\n","\n","optimizer_G = torch.optim.Adam(\n","    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2)\n",")\n","\n","optimizer_D_A = torch.optim.Adam(\n","    D_A.parameters(), lr=lr, betas=(b1, b2)\n",")\n","\n","optimizer_D_B = torch.optim.Adam(\n","    D_B.parameters(), lr=lr, betas=(b1, b2)\n",")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T03:26:53.389895Z","iopub.status.busy":"2021-08-17T03:26:53.38953Z","iopub.status.idle":"2021-08-17T03:26:53.409687Z","shell.execute_reply":"2021-08-17T03:26:53.408743Z","shell.execute_reply.started":"2021-08-17T03:26:53.389861Z"}},"source":["## Step 6. Learning Rate Scheduler Setting"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.097866Z","iopub.status.busy":"2021-08-17T15:58:46.097484Z","iopub.status.idle":"2021-08-17T15:58:46.11074Z","shell.execute_reply":"2021-08-17T15:58:46.109804Z","shell.execute_reply.started":"2021-08-17T15:58:46.097831Z"},"trusted":true},"outputs":[],"source":["n_epoches = 100\n","decay_epoch = 20\n","\n","lambda_func = lambda epoch: 1 - max(0, epoch-decay_epoch)/(n_epoches-decay_epoch)\n","\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_func)\n","lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_func)\n","lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_func)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T03:57:20.182081Z","iopub.status.busy":"2021-08-17T03:57:20.181606Z","iopub.status.idle":"2021-08-17T03:57:20.185286Z","shell.execute_reply":"2021-08-17T03:57:20.184648Z","shell.execute_reply.started":"2021-08-17T03:57:20.18205Z"}},"source":["## Step 7. DataLoader"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.112413Z","iopub.status.busy":"2021-08-17T15:58:46.112026Z","iopub.status.idle":"2021-08-17T15:58:46.12575Z","shell.execute_reply":"2021-08-17T15:58:46.124906Z","shell.execute_reply.started":"2021-08-17T15:58:46.112377Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, data_dir, start,end, transforms=None):\n","        A_dir = os.path.join(data_dir, 'BDD_daylight')\n","        B_dir = os.path.join(data_dir, 'BDD_night')\n","        \n","        self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[start:end]]\n","        self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[start:end]]\n","\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.files_B)\n","    \n","    def __getitem__(self, index):\n","        file_A = self.files_A[index]\n","        file_B = self.files_B[index]\n","        \n","        img_A = Image.open(file_A)\n","        img_B = Image.open(file_B)\n","        \n","        if self.transforms is not None:\n","            img_A = self.transforms(img_A)\n","            img_B = self.transforms(img_B)\n","        \n","        return img_A, img_B"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.127409Z","iopub.status.busy":"2021-08-17T15:58:46.126971Z","iopub.status.idle":"2021-08-17T15:58:46.521641Z","shell.execute_reply":"2021-08-17T15:58:46.52077Z","shell.execute_reply.started":"2021-08-17T15:58:46.127374Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms as transforms\n","from torch.utils.data import random_split\n","\n","\n","data_dir = r'C:\\Users\\IHG6KOR\\Desktop\\shiv\\ERD_projects\\domain_adaptation\\datasets'\n","\n","transforms_ = transforms.Compose([\n","   # transforms.Resize(int(256*1.12), Image.BICUBIC),\n","    #transforms.RandomCrop(256, 256),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","batch_size = 1\n","\n","master_dataset = ImageDataset(data_dir,0,500, transforms=transforms_)\n","# Define the sizes of train, validation, and test splits\n","train_size = int(0.7 * len(master_dataset))  # 70% for training\n","val_size = int(0.15 * len(master_dataset))   # 15% for validation\n","test_size = len(master_dataset) - train_size - val_size  # Remaining 15% for testing\n","\n","\n","# Split the dataset into train, validation, and test subsets\n","train_dataset, val_dataset, test_dataset = random_split(master_dataset, [train_size, val_size, test_size])\n","\n","\n","trainloader = DataLoader(\n","   train_dataset,\n","    batch_size = batch_size,\n","    shuffle = True,\n",")\n","testloader = DataLoader(\n","    test_dataset,\n","    batch_size = batch_size,\n","    shuffle = False,\n",")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-08-17T05:43:38.6353Z","iopub.status.busy":"2021-08-17T05:43:38.634944Z","iopub.status.idle":"2021-08-17T05:43:38.643016Z","shell.execute_reply":"2021-08-17T05:43:38.641759Z","shell.execute_reply.started":"2021-08-17T05:43:38.635271Z"}},"source":["## Step 8. Sample images to show"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.523373Z","iopub.status.busy":"2021-08-17T15:58:46.522882Z","iopub.status.idle":"2021-08-17T15:58:46.533844Z","shell.execute_reply":"2021-08-17T15:58:46.53305Z","shell.execute_reply.started":"2021-08-17T15:58:46.523334Z"},"trusted":true},"outputs":[],"source":["from torchvision.utils import make_grid\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","\n","def sample_images(real_A, real_B, figside=1.5):\n","    assert real_A.size() == real_B.size(), 'The image size for two domains must be the same'\n","    \n","    G_AB.eval()\n","    G_BA.eval()\n","    \n","    real_A = real_A.type(Tensor)\n","    fake_B = G_AB(real_A).detach()\n","    real_B = real_B.type(Tensor)\n","    fake_A = G_BA(real_B).detach()\n","    \n","    nrows = real_A.size(0)\n","    real_A = make_grid(real_A, nrow=nrows, normalize=True)\n","    fake_B = make_grid(fake_B, nrow=nrows, normalize=True)\n","    real_B = make_grid(real_B, nrow=nrows, normalize=True)\n","    fake_A = make_grid(fake_A, nrow=nrows, normalize=True)\n","    \n","    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1).cpu().permute(1, 2, 0)\n","    \n","    plt.figure(figsize=(figside*nrows, figside*4))\n","    plt.imshow(image_grid)\n","    plt.axis('off')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:46.535788Z","iopub.status.busy":"2021-08-17T15:58:46.535502Z","iopub.status.idle":"2021-08-17T15:58:48.352342Z","shell.execute_reply":"2021-08-17T15:58:48.351555Z","shell.execute_reply.started":"2021-08-17T15:58:46.535753Z"},"trusted":true},"outputs":[],"source":["# real_A, real_B = next(iter(testloader))\n","# sample_images(real_A, real_B)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 9. Training"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T15:58:48.361082Z","iopub.status.busy":"2021-08-17T15:58:48.360513Z","iopub.status.idle":"2021-08-17T16:13:55.677697Z","shell.execute_reply":"2021-08-17T16:13:55.67662Z","shell.execute_reply.started":"2021-08-17T15:58:48.361047Z"},"trusted":true},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 6.00 GiB total capacity; 18.79 GiB already allocated; 0 bytes free; 19.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# cycle loss\u001b[39;00m\n\u001b[0;32m     31\u001b[0m recov_A \u001b[38;5;241m=\u001b[39m G_BA(fake_B)\n\u001b[1;32m---> 32\u001b[0m recov_B \u001b[38;5;241m=\u001b[39m \u001b[43mG_AB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m loss_cycle_A \u001b[38;5;241m=\u001b[39m criterion_cycle(recov_A, real_A)\n\u001b[0;32m     34\u001b[0m loss_cycle_B \u001b[38;5;241m=\u001b[39m criterion_cycle(recov_B, real_B)\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[3], line 55\u001b[0m, in \u001b[0;36mGeneratorResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown(x)\n\u001b[1;32m---> 55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x)\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(x)\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\IHG6KOR\\Anaconda3\\envs\\gpu_activate\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 6.00 GiB total capacity; 18.79 GiB already allocated; 0 bytes free; 19.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["for epoch in range(n_epoches):\n","    for i, (real_A, real_B) in enumerate(trainloader):\n","        real_A, real_B = real_A.type(Tensor), real_B.type(Tensor)\n","        \n","        # groud truth\n","        out_shape = [real_A.size(0), 1, real_A.size(2)//D_A.scale_factor, real_A.size(3)//D_A.scale_factor]\n","        valid = torch.ones(out_shape).type(Tensor)\n","        fake = torch.zeros(out_shape).type(Tensor)\n","        \n","        \"\"\"Train Generators\"\"\"\n","        # set to training mode in the begining, beacause sample_images will set it to eval mode\n","        G_AB.train()\n","        G_BA.train()\n","        \n","        optimizer_G.zero_grad()\n","        \n","        fake_B = G_AB(real_A)\n","        fake_A = G_BA(real_B)\n","        \n","        # identity loss\n","        loss_id_A = criterion_identity(fake_B, real_A)\n","        loss_id_B = criterion_identity(fake_A, real_B)\n","        loss_identity = (loss_id_A + loss_id_B) / 2\n","        \n","        # GAN loss, train G to make D think it's true\n","        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid) \n","        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n","        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n","        \n","        # cycle loss\n","        recov_A = G_BA(fake_B)\n","        recov_B = G_AB(fake_A)\n","        loss_cycle_A = criterion_cycle(recov_A, real_A)\n","        loss_cycle_B = criterion_cycle(recov_B, real_B)\n","        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n","        \n","        # G totol loss\n","        loss_G = 5.0*loss_identity + loss_GAN + 10.0*loss_cycle\n","        \n","        loss_G.backward()\n","        optimizer_G.step()\n","        \n","        \"\"\"Train Discriminator A\"\"\"\n","        optimizer_D_A.zero_grad()\n","        \n","        loss_real = criterion_GAN(D_A(real_A), valid)\n","        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake)\n","        loss_D_A = (loss_real + loss_fake) / 2\n","        \n","        loss_D_A.backward()\n","        optimizer_D_A.step()\n","        \n","        \"\"\"Train Discriminator B\"\"\"\n","        optimizer_D_B.zero_grad()\n","        \n","        loss_real = criterion_GAN(D_B(real_B), valid)\n","        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake)\n","        loss_D_B = (loss_real + loss_fake) / 2\n","        \n","        loss_D_B.backward()\n","        optimizer_D_B.step()\n","    \n","    lr_scheduler_G.step()\n","    lr_scheduler_D_A.step()\n","    lr_scheduler_D_B.step()\n","    \n","    # test\n","    if (epoch+1) % 10 == 0:\n","        test_real_A, test_real_B = next(iter(testloader))\n","        sample_images(test_real_A, test_real_B)\n","\n","        loss_D = (loss_D_A + loss_D_B) / 2\n","        print(f'[Epoch {epoch+1}/{n_epoches}]')\n","        print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n","        print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')    "]},{"cell_type":"markdown","metadata":{},"source":["## Step 10. Generate Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T16:13:55.679792Z","iopub.status.busy":"2021-08-17T16:13:55.679376Z","iopub.status.idle":"2021-08-17T16:13:55.702252Z","shell.execute_reply":"2021-08-17T16:13:55.701317Z","shell.execute_reply.started":"2021-08-17T16:13:55.679748Z"},"trusted":true},"outputs":[],"source":["photo_dir = os.path.join(data_dir, 'photo_jpg')\n","files = [os.path.join(photo_dir, name) for name in os.listdir(photo_dir)]\n","len(files)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T16:13:55.703778Z","iopub.status.busy":"2021-08-17T16:13:55.703418Z","iopub.status.idle":"2021-08-17T16:13:55.708333Z","shell.execute_reply":"2021-08-17T16:13:55.707205Z","shell.execute_reply.started":"2021-08-17T16:13:55.703743Z"},"trusted":true},"outputs":[],"source":["save_dir = '../images'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T16:13:55.709978Z","iopub.status.busy":"2021-08-17T16:13:55.709618Z","iopub.status.idle":"2021-08-17T16:18:14.669934Z","shell.execute_reply":"2021-08-17T16:18:14.66908Z","shell.execute_reply.started":"2021-08-17T16:13:55.709942Z"},"trusted":true},"outputs":[],"source":["generate_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","to_image = transforms.ToPILImage()\n","\n","G_BA.eval()\n","for i in range(0, len(files), batch_size):\n","    # read images\n","    imgs = []\n","    for j in range(i, min(len(files), i+batch_size)):\n","        img = Image.open(files[j])\n","        img = generate_transforms(img)\n","        imgs.append(img)\n","    imgs = torch.stack(imgs, 0).type(Tensor)\n","    \n","    # generate\n","    fake_imgs = G_BA(imgs).detach().cpu()\n","    \n","    # save\n","    for j in range(fake_imgs.size(0)):\n","        img = fake_imgs[j].squeeze().permute(1, 2, 0)\n","        img_arr = img.numpy()\n","        img_arr = (img_arr - np.min(img_arr)) * 255 / (np.max(img_arr) - np.min(img_arr))\n","        img_arr = img_arr.astype(np.uint8)\n","        \n","        img = to_image(img_arr)\n","        _, name = os.path.split(files[i+j])\n","        img.save(os.path.join(save_dir, name))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-17T16:18:14.671525Z","iopub.status.busy":"2021-08-17T16:18:14.671164Z","iopub.status.idle":"2021-08-17T16:18:17.508148Z","shell.execute_reply":"2021-08-17T16:18:17.507156Z","shell.execute_reply.started":"2021-08-17T16:18:14.671459Z"},"trusted":true},"outputs":[],"source":["import shutil\n","shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":1475600,"sourceId":21755,"sourceType":"competition"}],"dockerImageVersionId":30121,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":4}
